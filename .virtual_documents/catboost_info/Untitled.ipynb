import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import Ridge
from sklearn.base import clone
import lightgbm as lgb
import xgboost as xgb
import catboost as cb
import tensorflow as tf
from tensorflow.keras import layers, models

# === Load data ===
train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
X = train.drop(columns=['Listening_Time_minutes'])
y = np.log1p(train['Listening_Time_minutes'])  # log transform
# Keep 'id' column in X_test
X_test = test[X.columns] # Select the same columns as X


# === Preprocessing ===
categorical = X.select_dtypes(include='object').columns.tolist()
numerical = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

preprocessor = ColumnTransformer([
    ('num', Pipeline([
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ]), numerical),
    ('cat', Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
    ]), categorical)
])

X_proc = np.asarray(preprocessor.fit_transform(X))
X_test_proc = np.asarray(preprocessor.transform(X_test))
y = np.asarray(y)

# === CNN input shape ===
X_cnn = X_proc.reshape((X_proc.shape[0], X_proc.shape[1], 1))
X_test_cnn = X_test_proc.reshape((X_test_proc.shape[0], X_test_proc.shape[1], 1))

# === CNN model ===
cnn_model = models.Sequential([
    layers.Conv1D(64, 3, activation='relu', input_shape=(X_cnn.shape[1], 1)),
    layers.Conv1D(64, 3, activation='relu'),
    layers.GlobalMaxPooling1D(),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)
])
cnn_model.compile(optimizer='adam', loss='mse')
cnn_model.fit(X_cnn, y, validation_split=0.2, epochs=50, batch_size=64, verbose=1)

cnn_preds = cnn_model.predict(X_test_cnn).flatten()
cnn_oof = cnn_model.predict(X_cnn).flatten()

# === Tree Model Wrapper ===
class ModelWrapper:
    def __init__(self, model, name):
        self.model = model
        self.name = name
        self.oof = None
        self.models = []
        self.test_preds = None

    def fit_predict(self, X, y, X_test, folds=5):
        kf = KFold(n_splits=folds, shuffle=True, random_state=42)
        self.oof = np.zeros(X.shape[0])
        self.test_preds = np.zeros(X_test.shape[0])
        
        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            model = clone(self.model)
            model.fit(X_train, y_train)
            self.oof[val_idx] = model.predict(X_val)
            self.test_preds += model.predict(X_test) / folds
            self.models.append(model)

        rmse = np.sqrt(mean_squared_error(y, self.oof))
        print(f"{self.name} CV RMSE: {rmse:.5f}")
        return self

# === Base models with tuned/best params ===
lgb_model = ModelWrapper(
    lgb.LGBMRegressor(n_estimators=1200, learning_rate=0.01, num_leaves=64, max_depth=8,
                      subsample=0.8, colsample_bytree=0.8, random_state=42),
    "LightGBM"
)

xgb_model = ModelWrapper(
    xgb.XGBRegressor(n_estimators=1200, learning_rate=0.01, max_depth=6,
                     subsample=0.8, colsample_bytree=0.8, random_state=42),
    "XGBoost"
)

cat_model = ModelWrapper(
    cb.CatBoostRegressor(iterations=1200, learning_rate=0.01, depth=6,
                         verbose=0, random_seed=42),
    "CatBoost"
)

# === Train base models ===
lgb_model.fit_predict(X_proc, y, X_test_proc)
xgb_model.fit_predict(X_proc, y, X_test_proc)
cat_model.fit_predict(X_proc, y, X_test_proc)

# === Stack predictions ===
stacked_X = np.vstack([
    lgb_model.oof,
    xgb_model.oof,
    cat_model.oof,
    cnn_oof
]).T

stacked_test = np.vstack([
    lgb_model.test_preds,
    xgb_model.test_preds,
    cat_model.test_preds,
    cnn_preds
]).T

# === Meta model ===
meta_model = Ridge(alpha=1.0)
meta_model.fit(stacked_X, y)
final_preds = meta_model.predict(stacked_test)
final_preds = np.expm1(final_preds)  # inverse log1p

# === Submission ===
submission = pd.DataFrame({
    'id': test['id'],
    'Listening_Time_minutes': final_preds
})
submission.to_csv('ensemble_submission.csv', index=False)
print("\nâœ… Ensemble submission saved as 'ensemble_submission.csv'")




